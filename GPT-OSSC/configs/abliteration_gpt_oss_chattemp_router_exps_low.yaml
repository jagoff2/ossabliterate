model: outputs/gpt_oss_dequant
measurements: outputs/gpt_oss_dequant_chattemp.refuse.pt
output: outputs/gpt_oss_dequant_ablated_chattemp_router_exps_low
targets:
- mlp.router.weight
- mlp.router.bias
- mlp.experts.gate_up_proj_blocks
- mlp.experts.down_proj_blocks
- mlp.experts.gate_up_proj_bias
- mlp.experts.down_proj_bias
- mlp.experts.gate_proj.weight
- mlp.experts.up_proj.weight
- mlp.experts.down_proj.weight
ablate:
- layer: 0
  measurement: 0
  scale: 0.513
  sparsity: 0.05
- layer: 0
  measurement: composite
  scale: 1.026
  sparsity: 0.05
- layer: 1
  measurement: 1
  scale: 0.711
  sparsity: 0.05
- layer: 1
  measurement: composite
  scale: 1.421
  sparsity: 0.05
- layer: 2
  measurement: 2
  scale: 1.085
  sparsity: 0.05
- layer: 2
  measurement: composite
  scale: 2.17
  sparsity: 0.05
- layer: 3
  measurement: 3
  scale: 1.584
  sparsity: 0.05
- layer: 3
  measurement: composite
  scale: 3.168
  sparsity: 0.05
- layer: 4
  measurement: 4
  scale: 2.145
  sparsity: 0.05
- layer: 4
  measurement: composite
  scale: 4.289
  sparsity: 0.05
- layer: 5
  measurement: 5
  scale: 2.641
  sparsity: 0.05
- layer: 5
  measurement: composite
  scale: 5.282
  sparsity: 0.05
- layer: 6
  measurement: 6
  scale: 2.804
  sparsity: 0.05
- layer: 6
  measurement: composite
  scale: 5.608
  sparsity: 0.05
- layer: 7
  measurement: 7
  scale: 3.241
  sparsity: 0.05
- layer: 7
  measurement: composite
  scale: 6.483
  sparsity: 0.05
- layer: 8
  measurement: 8
  scale: 3.142
  sparsity: 0.05
- layer: 8
  measurement: composite
  scale: 6.285
  sparsity: 0.05
- layer: 9
  measurement: 9
  scale: 3.316
  sparsity: 0.05
- layer: 9
  measurement: composite
  scale: 6.632
  sparsity: 0.05
- layer: 10
  measurement: 10
  scale: 3.77
  sparsity: 0.05
- layer: 10
  measurement: composite
  scale: 7.54
  sparsity: 0.05
- layer: 11
  measurement: 11
  scale: 3.516
  sparsity: 0.05
- layer: 11
  measurement: composite
  scale: 7.033
  sparsity: 0.05
- layer: 12
  measurement: 12
  scale: 3.591
  sparsity: 0.05
- layer: 12
  measurement: composite
  scale: 7.182
  sparsity: 0.05
- layer: 13
  measurement: 13
  scale: 3.555
  sparsity: 0.05
- layer: 13
  measurement: composite
  scale: 7.111
  sparsity: 0.05
- layer: 14
  measurement: 14
  scale: 3.997
  sparsity: 0.05
- layer: 14
  measurement: composite
  scale: 7.994
  sparsity: 0.05
- layer: 15
  measurement: 15
  scale: 3.567
  sparsity: 0.05
- layer: 15
  measurement: composite
  scale: 7.134
  sparsity: 0.05
- layer: 16
  measurement: 16
  scale: 4.0
  sparsity: 0.05
- layer: 16
  measurement: composite
  scale: 8.0
  sparsity: 0.05
- layer: 17
  measurement: 17
  scale: 3.378
  sparsity: 0.05
- layer: 17
  measurement: composite
  scale: 6.756
  sparsity: 0.05
- layer: 18
  measurement: 18
  scale: 3.498
  sparsity: 0.05
- layer: 18
  measurement: composite
  scale: 6.995
  sparsity: 0.05
- layer: 19
  measurement: 19
  scale: 3.19
  sparsity: 0.05
- layer: 19
  measurement: composite
  scale: 6.38
  sparsity: 0.05
- layer: 20
  measurement: 20
  scale: 3.351
  sparsity: 0.05
- layer: 20
  measurement: composite
  scale: 6.702
  sparsity: 0.05
- layer: 21
  measurement: 21
  scale: 2.844
  sparsity: 0.05
- layer: 21
  measurement: composite
  scale: 5.687
  sparsity: 0.05
- layer: 22
  measurement: 22
  scale: 2.688
  sparsity: 0.05
- layer: 22
  measurement: composite
  scale: 5.376
  sparsity: 0.05
- layer: 23
  measurement: 23
  scale: 2.178
  sparsity: 0.05
- layer: 23
  measurement: composite
  scale: 4.355
  sparsity: 0.05
