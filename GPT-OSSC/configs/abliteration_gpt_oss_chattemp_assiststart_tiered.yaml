model: outputs/gpt_oss_dequant
measurements: outputs/gpt_oss_dequant_chattemp_assiststart.refuse.pt
output: outputs/gpt_oss_dequant_ablated_chattemp_assiststart_tiered
targets:
- mlp.router.weight
- mlp.router.bias
- mlp.experts.gate_up_proj_blocks
- mlp.experts.down_proj_blocks
- mlp.experts.gate_up_proj_bias
- mlp.experts.down_proj_bias
- mlp.experts.gate_proj.weight
- mlp.experts.up_proj.weight
- mlp.experts.down_proj.weight
ablate:
- layer: 0
  measurement: 0
  scale: 0.0
  sparsity: 0.8
- layer: 0
  measurement: composite
  scale: 0.0
  sparsity: 0.8
- layer: 1
  measurement: 1
  scale: 0.113
  sparsity: 0.8
- layer: 1
  measurement: composite
  scale: 0.225
  sparsity: 0.8
- layer: 2
  measurement: 2
  scale: 0.107
  sparsity: 0.8
- layer: 2
  measurement: composite
  scale: 0.213
  sparsity: 0.8
- layer: 3
  measurement: 3
  scale: 0.132
  sparsity: 0.8
- layer: 3
  measurement: composite
  scale: 0.263
  sparsity: 0.8
- layer: 4
  measurement: 4
  scale: 0.138
  sparsity: 0.8
- layer: 4
  measurement: composite
  scale: 0.276
  sparsity: 0.8
- layer: 5
  measurement: 5
  scale: 0.147
  sparsity: 0.8
- layer: 5
  measurement: composite
  scale: 0.293
  sparsity: 0.8
- layer: 6
  measurement: 6
  scale: 0.178
  sparsity: 0.8
- layer: 6
  measurement: composite
  scale: 0.356
  sparsity: 0.8
- layer: 7
  measurement: 7
  scale: 0.163
  sparsity: 0.8
- layer: 7
  measurement: composite
  scale: 0.326
  sparsity: 0.8
- layer: 8
  measurement: 8
  scale: 0.192
  sparsity: 0.8
- layer: 8
  measurement: composite
  scale: 0.385
  sparsity: 0.8
- layer: 9
  measurement: 9
  scale: 0.217
  sparsity: 0.8
- layer: 9
  measurement: composite
  scale: 0.434
  sparsity: 0.8
- layer: 10
  measurement: 10
  scale: 0.764
  sparsity: 0.5
- layer: 10
  measurement: composite
  scale: 1.528
  sparsity: 0.5
- layer: 11
  measurement: 11
  scale: 0.823
  sparsity: 0.5
- layer: 11
  measurement: composite
  scale: 1.646
  sparsity: 0.5
- layer: 12
  measurement: 12
  scale: 0.856
  sparsity: 0.5
- layer: 12
  measurement: composite
  scale: 1.712
  sparsity: 0.5
- layer: 13
  measurement: 13
  scale: 1.05
  sparsity: 0.5
- layer: 13
  measurement: composite
  scale: 2.101
  sparsity: 0.5
- layer: 14
  measurement: 14
  scale: 1.098
  sparsity: 0.5
- layer: 14
  measurement: composite
  scale: 2.196
  sparsity: 0.5
- layer: 15
  measurement: 15
  scale: 1.144
  sparsity: 0.5
- layer: 15
  measurement: composite
  scale: 2.288
  sparsity: 0.5
- layer: 16
  measurement: 16
  scale: 1.056
  sparsity: 0.5
- layer: 16
  measurement: composite
  scale: 2.112
  sparsity: 0.5
- layer: 17
  measurement: 17
  scale: 0.4
  sparsity: 0.8
- layer: 17
  measurement: composite
  scale: 0.8
  sparsity: 0.8
- layer: 18
  measurement: 18
  scale: 0.373
  sparsity: 0.8
- layer: 18
  measurement: composite
  scale: 0.747
  sparsity: 0.8
- layer: 19
  measurement: 19
  scale: 0.371
  sparsity: 0.8
- layer: 19
  measurement: composite
  scale: 0.742
  sparsity: 0.8
- layer: 20
  measurement: 20
  scale: 0.319
  sparsity: 0.8
- layer: 20
  measurement: composite
  scale: 0.637
  sparsity: 0.8
- layer: 21
  measurement: 21
  scale: 0.302
  sparsity: 0.8
- layer: 21
  measurement: composite
  scale: 0.604
  sparsity: 0.8
- layer: 22
  measurement: 22
  scale: 0.332
  sparsity: 0.8
- layer: 22
  measurement: composite
  scale: 0.664
  sparsity: 0.8
- layer: 23
  measurement: 23
  scale: 0.301
  sparsity: 0.8
- layer: 23
  measurement: composite
  scale: 0.602
  sparsity: 0.8
